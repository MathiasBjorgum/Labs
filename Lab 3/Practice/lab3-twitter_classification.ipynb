{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faec64f9-7525-4911-96b8-23a6846bc403",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Practice - Twitter classifier\n",
    "With the Tweet Corpus from two Twitter accounts (archives from Ariana Grande and Trump)\n",
    "\n",
    "2) \n",
    "3) Set up and fit a linear model and predict which account an input tweet is from and its probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d03887a9-6f2a-41f4-9389-b13bb3544b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff326d4-30df-49ae-bb6c-379be4a47d6a",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "You may find these useful in the lab. Feel free to modify for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b872392-ee78-41f3-b2d6-6cdf776a084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(data, probs, label1, label2, n=10):\n",
    "    percent = lambda x: \"{}%\".format(round(x*100, 1))\n",
    "    \n",
    "    for text, pred in list(zip(data, probs))[:n]:\n",
    "        print(\"{}\\n{}: {} / {}: {}\\n{}\".format(\n",
    "            text,\n",
    "            label1,\n",
    "            percent(pred[0]),\n",
    "            label2,\n",
    "            percent(pred[1]),\n",
    "            \"-\"*50  # to print a line\n",
    "        ))\n",
    "        \n",
    "def predict(model, vectorizer, data, all_predictions=False):\n",
    "    data = vectorizer.transform(data)\n",
    "    if all_predictions:\n",
    "        return model.predict_proba(data)\n",
    "    else:\n",
    "        return model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44c2e7-c49d-4470-90a6-f5493fb19860",
   "metadata": {},
   "source": [
    "### Cleaning function\n",
    "Create a simple text cleaning function, as tweets are sensitive to major reformatting. You may experiment with this statement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32521d28-e16a-415c-b50b-a8224d956f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_text_clean(text):\n",
    "    tokens =  TweetTokenizer().tokenize(str(text).lower())\n",
    "    stop = stopwords.words(\"english\")\n",
    "    return \" \".join([w for w in tokens if w.lower() not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0751a34-9e92-420e-8a8e-f60f2a2513b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch data from /twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "faa0d488-c24e-4bce-a500-96e5384a1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(name, test_size=0.1):\n",
    "    with open(\"twitter_data/{}.json\".format(name)) as f:\n",
    "        #raw_tweets = json.load(f)\n",
    "        tweets = [t.get(\"text\") for t in json.load(f)]\n",
    "        #tweets = list(map(lambda x: x.get(\"text\"), raw_tweets))\n",
    "        cleaned = [twitter_text_clean(t) for t in tweets]\n",
    "        #cleaned = list(map(twitter_text_clean, tweets))\n",
    "        \n",
    "        return train_test_split(cleaned, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a930c26-3f85-41eb-a0c0-bf3f68523dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 320\n"
     ]
    }
   ],
   "source": [
    "# TODO: experiment with this parameter!\n",
    "\"\"\"\n",
    "initially gather a train and test set of each tweet file.\n",
    "below, we use train to create another test set to evaluate the model\n",
    "\n",
    "this means the two test datasets below \\\n",
    "are completely unseen to the model we train\n",
    "\"\"\"\n",
    "test_split = 0.2\n",
    "ariana_train, ariana_test = tweets(\"ariana\", test_size=test_split)\n",
    "trump_train, trump_test = tweets(\"trump\", test_size=test_split)\n",
    "\n",
    "y = [1]*len(ariana_train) + [0]*len(trump_train)\n",
    "x = ariana_train + trump_train\n",
    "print(\"Train samples: {}\".format(len(x)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.1, random_state=4310)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eaa5e-140c-4958-b14d-3b919a99266b",
   "metadata": {},
   "source": [
    "### TF-IDF + logistic regression\n",
    "- Vectorize the tweets (e.g. with Count Vectorizer or TF-IDF Vectorizer).\n",
    "- Logistic regression is neat because it spits out whether something is true or not.\n",
    "    - This is exactly what we want in this case, to determine between two types of tweet sources (1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dec3930-b21b-43fb-adb4-bfa6d3e1fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0]\n",
      " [ 0 16]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# define regression and fit\n",
    "LR = LogisticRegression()\n",
    "LR.fit(vectorizer.fit_transform(X_train), y_train)\n",
    "\n",
    "# evaluate by confusion matrix \n",
    "y_pred = predict(LR, vectorizer, X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e5af6a-ba13-436b-8236-60880f15af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@kioshiwarrior u angel omg video made happy . thank u every minute . ‚Äô watchi ‚Ä¶ https://t.co/aaqtky0fst\n",
      "Trump: 32.0% / Ariana: 68.0%\n",
      "--------------------------------------------------\n",
      "@imhvogue yeeeee thank u ! ! !\n",
      "Trump: 36.9% / Ariana: 63.1%\n",
      "--------------------------------------------------\n",
      "love u much ‚Äô start pls https://t.co/syh5atqhzw\n",
      "Trump: 15.6% / Ariana: 84.4%\n",
      "--------------------------------------------------\n",
      "‚Äô wait give u album month\n",
      "Trump: 41.8% / Ariana: 58.2%\n",
      "--------------------------------------------------\n",
      "https://t.co/nob4qnhpkx\n",
      "Trump: 4.0% / Ariana: 96.0%\n",
      "--------------------------------------------------\n",
      "rt @teamariana : r . e . . full fragrance commercial ü§ç watch : https://t.co/dvwaqrsilm https://t.co/ffk0blmgnq\n",
      "Trump: 21.8% / Ariana: 78.2%\n",
      "--------------------------------------------------\n",
      "love u thankfulll\n",
      "Trump: 18.9% / Ariana: 81.1%\n",
      "--------------------------------------------------\n",
      "congratulations incredible deserving team @tbhits @amnija_ @londonondatrack #positions ! ! ! thank ‚Ä¶ https://t.co/f1c6u5j5dz\n",
      "Trump: 23.3% / Ariana: 76.7%\n",
      "--------------------------------------------------\n",
      "like sunsets like head chest\n",
      "Trump: 51.7% / Ariana: 48.3%\n",
      "--------------------------------------------------\n",
      "@imhdream @hbwtears looked good ear\n",
      "Trump: 41.2% / Ariana: 58.8%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ariana_prob = predict(LR, vectorizer, ariana_test, all_predictions=True)\n",
    "print_examples(ariana_test, ariana_prob, \"Trump\", \"Ariana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5064f616-39ac-432d-ba69-4dc8297397a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @realdonaldtrump : spoke prime minister @borisjohnson united kingdom . thankful friendship support ‚Ä¶\n",
      "Trump: 77.1% / Ariana: 22.9%\n",
      "--------------------------------------------------\n",
      "rt @realdonaldtrump : pelosi holding stimulus , republicans !\n",
      "Trump: 81.2% / Ariana: 18.8%\n",
      "--------------------------------------------------\n",
      "rt @realdonaldtrump : morocco recognized united states 1777 . thus fitting recognize sovereignty western saha ‚Ä¶\n",
      "Trump: 82.9% / Ariana: 17.1%\n",
      "--------------------------------------------------\n",
      "rt @whitehouse : president @realdonaldtrump wheels minnesota ! https://t.co/h3hgy0skfc\n",
      "Trump: 90.8% / Ariana: 9.2%\n",
      "--------------------------------------------------\n",
      "rt @realdonaldtrump : https://t.co/wheb2u37mi\n",
      "Trump: 81.0% / Ariana: 19.0%\n",
      "--------------------------------------------------\n",
      "rt @realdonaldtrump : https://t.co/cglqrmhtv4\n",
      "Trump: 81.0% / Ariana: 19.0%\n",
      "--------------------------------------------------\n",
      "rt @whitehouse : \" amy coney barrett decide cases based text constitution written . amy said , judge take ‚Ä¶\n",
      "Trump: 75.4% / Ariana: 24.6%\n",
      "--------------------------------------------------\n",
      "rt @realdonaldtrump : great news ! pac - 12 football back fall ! congrats players , families , coaches , universi ‚Ä¶\n",
      "Trump: 83.3% / Ariana: 16.7%\n",
      "--------------------------------------------------\n",
      "rt @realdonaldtrump : ‚Äú radical left trying hard undermine christopher columbus legacy . great italian opened new chapter h ‚Ä¶\n",
      "Trump: 81.1% / Ariana: 18.9%\n",
      "--------------------------------------------------\n",
      "rt @whitehouse : \" marched white house understand ‚Äî protect lives black americans americans , ‚Ä¶\n",
      "Trump: 76.2% / Ariana: 23.8%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trump_prob = predict(LR, vectorizer, trump_test, all_predictions=True)\n",
    "print_examples(trump_test, trump_prob, \"Trump\", \"Ariana\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b8f20c097e32b53f09a95007ec526e0eb5f6178dd7117c218d8f10eacb6c81e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
