{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620f2305-5877-4757-a192-ca477293b61c",
   "metadata": {},
   "source": [
    "# Lab 3\n",
    "We'll use this lab as an experiment of using a single file where you fill in codeblocks where necessary. They will be available as .py and .ipynb. Using the latter, or Jupyter Notebook, is highly recommended, as it provides substantially better feedback.\n",
    "\n",
    "\n",
    "Provide your outputs in a simple report, along with textual answers.\n",
    "\n",
    "\n",
    "The idea behind this format is to clarify what sort of output is required, as all answers run on tests based in the `tests.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb11d99c-3397-400d-bbcb-683c0f28a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "# feel free to import from modules of sklearn and nltk later\n",
    "# e.g., from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800315b-4ea7-467b-8b1d-fbe945565bfe",
   "metadata": {},
   "source": [
    "## Exercise 1 - Gender detection of names\n",
    "In NLTK you'll find the corpus `corpus.names`. A set of 5000 male and 3000 female names.\n",
    "1) Select a ratio of train/test data (based on experiences from previous labs perhaps?)\n",
    "2) Build a feature extractor function\n",
    "3) Build two classifiers:\n",
    "    - Decision tree\n",
    "    - NaÃ¯ve bayes\n",
    "    \n",
    "Finally, write code to evaluate the classifiers. Explain your results, and what do you think would change if you altered your feature extractor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fedc388-5e0d-4e9e-8470-ab141993608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class GenderDataset:\n",
    "    def __init__(self):\n",
    "        self.names = nltk.corpus.names\n",
    "        self.data = None\n",
    "        self.build()\n",
    "\n",
    "    def make_labels(self, gender: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        this function is to help you get started\n",
    "        based on the passed gender, as you can fetch from the file ids,\n",
    "        we return a tuple of (name, gender) for each name\n",
    "        \n",
    "        use this in `build` below, or do your own thing completely :)\n",
    "        \"\"\"\n",
    "        return [(n, gender) for n in self.names.words(gender + \".txt\")]\n",
    "    \n",
    "    def build(self) -> None:\n",
    "        \"\"\"\n",
    "        combine the data in \"male\" and \"female\" into one\n",
    "        remember to randomize the order\n",
    "        \"\"\"\n",
    "        data = self.make_labels(\"male\")\n",
    "        data.extend(self.make_labels(\"female\"))\n",
    "        random.shuffle(data)\n",
    "        self.data = data\n",
    "    \n",
    "    def split(self, ratio):\n",
    "        return train_test_split(self.data, test_size=ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f99b277-58e2-41f4-b5cf-5cd7f1e1a1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, classifier: nltk.ClassifierI):\n",
    "        self.classifier = classifier\n",
    "        self.model = None\n",
    "    \n",
    "    def train(self, data):\n",
    "        self.model = self.classifier.train(data)\n",
    "        \n",
    "    def test(self, data):\n",
    "        return nltk.classify.accuracy(self.model, data)\n",
    "    \n",
    "    def train_and_evaluate(self, train, test):\n",
    "        self.train(train)\n",
    "        return self.test(test)\n",
    "        \n",
    "    def show_features(self):\n",
    "        # OPTIONAL\n",
    "        pass\n",
    "\n",
    "                                 \n",
    "class FeatureExtractor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.features = []  \n",
    "        \n",
    "        self.build()\n",
    "                 \n",
    "    @staticmethod\n",
    "    def text_to_features(name):\n",
    "        # TODO: create a dict of features from a name\n",
    "        return {\n",
    "            \"last_letter\": name[-1],\n",
    "            \"first_letter\": name[1]\n",
    "        }\n",
    "    \n",
    "    def build(self):\n",
    "        for name, gender in self.data:\n",
    "            self.features.append((self.text_to_features(name), gender))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae27ee-b7af-4961-87c9-1082174243e3",
   "metadata": {},
   "source": [
    "Note: you should achieve an accuracy of well above 70%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd040ab-42c4-42ed-ad8c-b5fbf4bfa718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: decision_tree\tAccuracy: 0.7559748427672957\n",
      "Model: naive_bayes\tAccuracy: 0.7433962264150943\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.1  # TODO: modify\n",
    "train, test = GenderDataset().split(ratio=split_ratio)\n",
    "\n",
    "classifiers = {\n",
    "    \"decision_tree\": Classifier(nltk.DecisionTreeClassifier), # TODO\n",
    "    \"naive_bayes\": Classifier(nltk.NaiveBayesClassifier), # TODO\n",
    "}\n",
    "\n",
    "train_set = FeatureExtractor(train).features\n",
    "test_set = FeatureExtractor(test).features\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    acc = classifier.train_and_evaluate(train_set, test_set)\n",
    "    print(f\"Model: {name}\\tAccuracy: {acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get an accuracy of around 70-75% for both classifiers. The results vary for each time i run the code, because of the random shuffeling. That being said, the naive bayes classifier usally gives a better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acdd9d-789d-4d05-bad4-35141ffa5e4b",
   "metadata": {},
   "source": [
    "## Exercise 2 - Spam or ham\n",
    "Spam or ham is referred to a mail being spam or regular (\"ham\"). Follow the instructions and implement the `TODOs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb643e2-3d3c-487f-a953-092fb334c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv(\n",
    "    'spam.csv',\n",
    "    usecols=[\"v1\", \"v2\"],\n",
    "    encoding=\"latin-1\"\n",
    ").rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "\n",
    "print(spam.label.value_counts())\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e663bc-07ce-4593-8298-350afaee23fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" TODO: transform label to numerical\n",
    "Expected output:\n",
    "0    4825\n",
    "1     747\n",
    "Name: label, dtype: int64\n",
    "\n",
    "hint: you can use \"apply\" or \"replace\" for a column in pandas\n",
    "\"\"\"\n",
    "spam[\"label\"].replace({\"ham\": 0, \"spam\": 1}, inplace=True) # your transformation goes here\n",
    "\n",
    "spam.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027995b9-aee1-4d67-8fa1-f6cd3afe1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    def __init__(self, text):\n",
    "        self.tokenize(text) # TODO: tokenize\n",
    "        self.stemmer = nltk.stem.PorterStemmer() # TODO: incorporate a stemmer of your choice\n",
    "        self.stopwords = nltk.corpus.stopwords.words(\"english\")  # TODO: you've done this a few times\n",
    "        self.lem = nltk.stem.WordNetLemmatizer()  # TODO: lemmatizer\n",
    "    \n",
    "    \"\"\"\n",
    "    Create small functions to replace your tokens (self.text)\n",
    "    iteratively. Such as a lowercase function.\n",
    "    \"\"\"\n",
    "    def tokenize(self, text):\n",
    "        # self.text = [word for word in text.split()]\n",
    "        self.text = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.text = [word.lower() for word in self.text]\n",
    "    \n",
    "    def lemmatize(self):\n",
    "        self.text = [self.lem.lemmatize(word) for word in self.text]\n",
    "\n",
    "    def stem(self):\n",
    "        self.text = [self.stemmer.stem(word) for word in self.text]\n",
    "\n",
    "    def remove_stopwords(self):\n",
    "        self.text = [word for word in self.text if word not in self.stopwords]\n",
    "\n",
    "    def clean(self, lem: bool = False, stem: bool = False):\n",
    "        self.lowercase()\n",
    "        self.remove_stopwords()\n",
    "        \"\"\"\n",
    "        TODO: populate with your defined cleaning functions here\n",
    "        perhaps you want some conditional values to\n",
    "        control which functions to use?\n",
    "        \"\"\"\n",
    "        if lem:\n",
    "            self.lemmatize()\n",
    "        if stem:\n",
    "            self.stem()\n",
    "        \n",
    "        # finally, return it as a text \n",
    "        return \" \".join(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9cac1b-141f-43c6-939b-beddea37ade9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_spam = spam.copy()\n",
    "clean = lambda text: TextCleaner(text).clean(stem=True)\n",
    "spam.text = spam.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52288899-68e3-4d84-bd02-609419b14673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point , crazi .. avail bugi n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar ... joke wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say earli hor ... u c alreadi say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah n't think goe usf , live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  go jurong point , crazi .. avail bugi n great ...\n",
       "1      0                      ok lar ... joke wif u oni ...\n",
       "2      1  free entri 2 wkli comp win fa cup final tkt 21...\n",
       "3      0        u dun say earli hor ... u c alreadi say ...\n",
       "4      0         nah n't think goe usf , live around though"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b2bad2-d747-49fe-8876-d8bf19e10095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "split_ratio = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    spam.text, spam.label, test_size=split_ratio, random_state=4310)\n",
    "\n",
    "\n",
    "# vectorize with sklearn\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit the vectorizer to your training data\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: set up a multinomial classifier\n",
    "classifier = MultinomialNB()\n",
    "if classifier:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "vectorized = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f9bdb3-b4b4-40ba-9faa-d7304c741401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, vectorizer, data, all_predictions=False):\n",
    "    data = vectorizer.transform(data) # TODO apply the transformation from the vectorizer to test data \n",
    "    if all_predictions:\n",
    "        return model.predict_proba(data)\n",
    "    else:\n",
    "        return model.predict(data)\n",
    "\n",
    "def print_examples(data, probs, label1, label2, n=10):\n",
    "    percent = lambda x: \"{}%\".format(round(x*100, 1))\n",
    "\n",
    "    for text, pred in list(zip(data, probs))[:n]:\n",
    "        print(f\"{text} \\n{label1}: {percent(pred[0])} / {label2}: {percent(pred[1])}\\n{'-' * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1329d63-5ed4-4648-adca-ab36567095a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world famamu .... \n",
      "ham: 95.6% / spam: 4.4%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\\aww must nearli dead ! well jez iscom todo workand whilltak forev ! \\ '' '' \n",
      "ham: 95.2% / spam: 4.8%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[[488   0]\n",
      " [ 18  52]]\n",
      "Recall=0.74\n",
      "Precision=1.0\n"
     ]
    }
   ],
   "source": [
    "if classifier:\n",
    "    y_probas = predict(classifier, vectorizer, X_test, all_predictions=True)\n",
    "    print_examples(X_test, y_probas, \"ham\", \"spam\", n = 2)\n",
    "\n",
    "    y_pred = predict(classifier, vectorizer, X_test)\n",
    "    # TODO display a confusion matrix on the test set vs predictions\n",
    "    confusion_mat = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "    print(confusion_mat)\n",
    "\n",
    "    # show precision and recall in a confusion matrix\n",
    "    tn, fp, fn, tp = confusion_mat.ravel()\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    print(f\"Recall={round(recall, 2)}\\nPrecision={round(precision, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a39c5-f75f-4298-ac1d-48d11604a063",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 3 - Word features\n",
    "Word features can be very useful for performing document classification, since the words that appear in a document give a strong indication of what its semantic content is. However, many words occur very infrequently, and some of the most informative words in a document may never have occurred in our training data. One solution is to make use of a lexicon, which describes how different words relate to each other.\n",
    "\n",
    "Your task:\n",
    "- Use the WordNet lexicon and augment the movie review document classifier (See NLTK book, Ch. 6, section 1.3) to use features that generalize the words that appear in a document, making it more likely that they will match words found in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea34bc3-b944-4850-9f20-104898a6cbc2",
   "metadata": {},
   "source": [
    "Download wordnet and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51d70ac-637e-442d-abf0-d9a81a3917fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import wordnet as wn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88196d95-5ebc-4f64-b872-5f68cb1634b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toad\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import random\n",
    "\n",
    "def word_to_syn(word) -> str:\n",
    "    '''Returns a synonym for a word. If no synonym is found the function returns the word itself'''\n",
    "\n",
    "    all_lemmas = []\n",
    "    for syn in wn.synsets(word):\n",
    "        all_lemmas.append(syn.lemma_names())\n",
    "\n",
    "    if len(all_lemmas) == 0:\n",
    "        return word\n",
    "\n",
    "    first_synset = all_lemmas[0]\n",
    "\n",
    "    if len(first_synset) == 0:\n",
    "        return word\n",
    "\n",
    "    if len(first_synset) > 1:\n",
    "        if word in first_synset:\n",
    "            first_synset.remove(word)\n",
    "        return first_synset[0]\n",
    "\n",
    "    return first_synset[0]\n",
    "\n",
    "print(word_to_syn(\"frog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23d9d4a7-c64f-4509-87c7-77fb3ed2fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this is from Ch. 6, sec. 1.3, with slight modifications\n",
    "note that word_to_syn(word) (from the above implementation)\n",
    "is in the beginning of the following function\n",
    "\"\"\"\n",
    "documents = [([word_to_syn(word) for word in list(movie_reviews.words(fileid))], category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "n_most_freq = 2000\n",
    "word_features = list(all_words)[:n_most_freq]\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "28f2b8d0-d8f4-44f6-b61b-c7ab867ffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "\n",
    "split_ratio = 0.1\n",
    "train_set, test_set = train_test_split(featuresets, test_size=split_ratio)\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier\n",
    "model = classifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fc056fa9-9cbb-492d-90b3-75014a89e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coder', 'computer_programing', 'computer_programmer', 'computer_programming', 'program', 'programing', 'programme', 'programmer', 'programming', 'scheduling', 'software_engineer']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def synset_expansion(words: List[str]) -> List:\n",
    "    '''Returns a list of all lemmas given an input wordlist'''\n",
    "    all_lemmas = []\n",
    "\n",
    "    for word in words:\n",
    "        for syn in wn.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                all_lemmas.append(lemma.name())\n",
    "\n",
    "\n",
    "    all_lemmas = [word.lower() for word in (set(all_lemmas))]\n",
    "\n",
    "    return sorted(all_lemmas)\n",
    "\n",
    "expanded_word_features = synset_expansion(word_features)\n",
    "print(synset_expansion([\"programming\", \"coder\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "23b87242-0f80-49d0-b9d2-d9de9a647938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assertions to test your code :-)\n",
    "assert sorted(synset_expansion([\"pc\"])) == [\"microcomputer\", \"pc\", \"personal_computer\"]\n",
    "assert sorted(synset_expansion([\"programming\", \"coder\"])) == [\n",
    "    'coder',\n",
    "    'computer_programing',\n",
    "    'computer_programmer',\n",
    "    'computer_programming',\n",
    "    'program',\n",
    "    'programing',\n",
    "    'programme',\n",
    "    'programmer',\n",
    "    'programming',\n",
    "    'scheduling',\n",
    "    'software_engineer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3ac2370a-6e85-4b3e-a9e4-5f4dbeab15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(lame) = True              neg : pos    =     10.5 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.2 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.1 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =      6.3 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.6 : 1.0\n",
      "Accuracy:  0.81\n"
     ]
    }
   ],
   "source": [
    "doc_featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "doc_train_set, doc_test_set = train_test_split(doc_featuresets, test_size=0.1)\n",
    "\n",
    "doc_model = model.train(doc_train_set)\n",
    "doc_model.show_most_informative_features(5)\n",
    "print(\"Accuracy: \", nltk.classify.accuracy(doc_model, doc_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "714ec224-e865-47ee-976a-d72d5184a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_features(reviews):\n",
    "    review_words = set(reviews)\n",
    "    features = {}\n",
    "    for word in expanded_word_features:\n",
    "        if word not in word_features:\n",
    "            features['synset({})'.format(word)] = (word in review_words)\n",
    "        features['contains({})'.format(word)] = (word in review_words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e280bf-409d-4444-9d70-bf95a8ba2d34",
   "metadata": {},
   "source": [
    "Question: do you see any issues with including the synsets? Experiment a bit with different words and verify your ideas.\n",
    "\n",
    "Including this expanded synsets might lead to the tree becoming to big and including words that does not have the same meaning, or even worse, have the opposite meaning. One shold tread lightly when doing this and perhaps include a validation set to validate that this expansion makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5a88411-251a-4acd-b83c-ed287c17c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(feeble) = True              neg : pos    =     10.9 : 1.0\n",
      "          synset(feeble) = True              neg : pos    =     10.9 : 1.0\n",
      "     contains(interpret) = True              pos : neg    =      8.4 : 1.0\n",
      "       synset(interpret) = True              pos : neg    =      8.4 : 1.0\n",
      "     contains(illogical) = True              neg : pos    =      8.3 : 1.0\n",
      "       contains(misfire) = True              neg : pos    =      8.3 : 1.0\n",
      "       synset(illogical) = True              neg : pos    =      8.3 : 1.0\n",
      "         synset(misfire) = True              neg : pos    =      8.3 : 1.0\n",
      "           contains(bit) = True              pos : neg    =      7.7 : 1.0\n",
      "         contains(chaff) = True              neg : pos    =      7.6 : 1.0\n",
      "Accuracy:  0.73\n"
     ]
    }
   ],
   "source": [
    "# warning: this may take some time to run\n",
    "lex_featuresets = [(lexicon_features(d), c) for (d, c) in documents]\n",
    "lex_train_set, lex_test_set = train_test_split(lex_featuresets, test_size=0.1)\n",
    "lex_model = model.train(lex_train_set)  # the same classifier as you defined above\n",
    "lex_model.show_most_informative_features()\n",
    "print(\"Accuracy: \", nltk.classify.accuracy(lex_model, lex_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca65772",
   "metadata": {},
   "source": [
    "```\n",
    "Most Informative Features\n",
    "        contains(feeble) = True              neg : pos    =     10.9 : 1.0\n",
    "          synset(feeble) = True              neg : pos    =     10.9 : 1.0\n",
    "     contains(interpret) = True              pos : neg    =      8.4 : 1.0\n",
    "       synset(interpret) = True              pos : neg    =      8.4 : 1.0\n",
    "     contains(illogical) = True              neg : pos    =      8.3 : 1.0\n",
    "       contains(misfire) = True              neg : pos    =      8.3 : 1.0\n",
    "       synset(illogical) = True              neg : pos    =      8.3 : 1.0\n",
    "         synset(misfire) = True              neg : pos    =      8.3 : 1.0\n",
    "           contains(bit) = True              pos : neg    =      7.7 : 1.0\n",
    "         contains(chaff) = True              neg : pos    =      7.6 : 1.0\n",
    "Accuracy:  0.73\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53b328-bbcb-4895-9047-ebaa3e9b543c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 4 -- Experimentation\n",
    "This exercise is largely open to experiment with and testing your skills thus far!\n",
    "Large websites are an ideal place to look for large corpora of natural language. In this exercise, you're free to implement what you've learned on real-world data, mined from youtube (see `youtube_data`). Reuse classes defined earlier on in the exercise if you want.\n",
    "\n",
    "The only requirement here is to **use a classifier not previously used in the exercise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17afb16-42bb-4df2-a817-9dcc1264d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "yt_data_path = os.path.join(os.getcwd(), \"youtube_data\")\n",
    "df = pd.read_csv(os.path.join(os.path.join(yt_data_path, \"videos.csv\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591bd9b",
   "metadata": {},
   "source": [
    "I choose to clean this data by filtering on the columns that i want to keep, and drop all duplicate entries of the variable `video_id`. After looking in the dataset i noticed that almost all videos were representet multiple times, with a slightly different `trending_date` and different `views, likes, dislikes`. In this task i will try to predict a category based on the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869ba0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[[\"video_id\", \"title\", \"category_id\",\"description\"]].drop_duplicates(\"video_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee3448ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"category_id\"] = clean_df[\"category_id\"].astype(\"category\")\n",
    "clean_df[\"description\"] = clean_df[\"description\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ed535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    1619\n",
       "10     799\n",
       "26     595\n",
       "23     547\n",
       "25     505\n",
       "22     498\n",
       "17     451\n",
       "28     380\n",
       "1      318\n",
       "27     250\n",
       "15     138\n",
       "20     103\n",
       "2       70\n",
       "19      60\n",
       "29      14\n",
       "43       4\n",
       "Name: category_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.category_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0713b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = lambda text: TextCleaner(str(text)).clean(stem=True)\n",
    "clean_df[\"description\"] = clean_df[\"description\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ec6073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     6351\n",
       "unique    6196\n",
       "top        nan\n",
       "freq       102\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[\"description\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84803fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na_df = clean_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c87c00",
   "metadata": {},
   "source": [
    "I notice that the dataset contains some values that is `NaN`, but pandas `df.dropna()` function does not seem to work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6208c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "split_ratio = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    clean_df.description, clean_df.category_id, test_size=split_ratio, random_state=4310\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3938d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_classifier = SVC()\n",
    "if SVC_classifier:\n",
    "    SVC_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aaa09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVC_classifier.predict(vectorizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6641fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.34      0.50        80\n",
      "           2       0.00      0.00      0.00        14\n",
      "          10       0.93      0.83      0.88       199\n",
      "          15       0.93      0.41      0.57        32\n",
      "          17       0.97      0.76      0.85       113\n",
      "          19       1.00      0.07      0.12        15\n",
      "          20       1.00      0.12      0.22        24\n",
      "          22       0.82      0.39      0.53       119\n",
      "          23       0.98      0.70      0.82       142\n",
      "          24       0.49      0.96      0.65       413\n",
      "          25       0.93      0.62      0.74       125\n",
      "          26       0.80      0.72      0.76       143\n",
      "          27       1.00      0.65      0.79        68\n",
      "          28       0.90      0.49      0.64        96\n",
      "          29       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.70      1588\n",
      "   macro avg       0.73      0.44      0.50      1588\n",
      "weighted avg       0.79      0.70      0.69      1588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f66308",
   "metadata": {},
   "source": [
    "From this i get the output:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.93      0.34      0.50        80\n",
    "           2       0.00      0.00      0.00        14\n",
    "          10       0.93      0.83      0.88       199\n",
    "          15       0.93      0.41      0.57        32\n",
    "          17       0.97      0.76      0.85       113\n",
    "          19       1.00      0.07      0.12        15\n",
    "          20       1.00      0.12      0.22        24\n",
    "          22       0.82      0.39      0.53       119\n",
    "          23       0.98      0.70      0.82       142\n",
    "          24       0.49      0.96      0.65       413\n",
    "          25       0.93      0.62      0.74       125\n",
    "          26       0.80      0.72      0.76       143\n",
    "          27       1.00      0.65      0.79        68\n",
    "          28       0.90      0.49      0.64        96\n",
    "          29       0.00      0.00      0.00         3\n",
    "          43       0.00      0.00      0.00         2\n",
    "\n",
    "    accuracy                           0.70      1588\n",
    "   macro avg       0.73      0.44      0.50      1588\n",
    "weighted avg       0.79      0.70      0.69      1588\n",
    "```\n",
    "\n",
    "This showes us that the precision is mostly good over all the categories. Category 2, 29 and 43 were unable to be calculated, and therefore is set to 0. This might be because of the random selection not selecting enough of theese categories to the test set."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b8f20c097e32b53f09a95007ec526e0eb5f6178dd7117c218d8f10eacb6c81e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
